{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6230a727",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation\n",
    "\n",
    "This is the takehome notebook for the NLP engineer position at Contenda. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162fb65",
   "metadata": {},
   "source": [
    "## How did you allocate your time?\n",
    "* 15 minutes familiarizing myself with the existing code and data.\n",
    "* 20 minutes setting up a conda environment with jupyter and the dependencies.\n",
    "* 40 minutes running the existing code to get a model trained and look at some initial results on the train data.\n",
    "* 40 minutes doing some iteration and experimentation, including some refactors and annotations of the code, reviewing the output and adding some improvements to remove stopwords, and experimenting with different numbers of topics\n",
    "* 30 minutes re-formatting the output into a table format\n",
    "* 20 minutes experimenting with a TSNE dimensionality reduction for a clustering visualization.\n",
    "* 40 minutes for this writeup (Yes, I went over the time a bit!)\n",
    "\n",
    "## What are the tradeoffs between training a model on transcripts as a corpus versus written articles?\n",
    "First of all, it seems that there's a strong motivation to develop models that can work well on transcripts, as the transcripts represent the content of media for which internal discoverability might be challenging. Because we're motivated to build models that help process these kinds of media, we'll see better results if we develop models that work well in that domain.\n",
    "\n",
    "The differences in style and register between transcribed speech and formal written language are quite significant. Speech is often in a more informal register, so we'll see use of much more casual language than we'd expect in an article. We'll also expect to see much looser syntax, interjections, disfluencies and edits we wouldn't expect in written language.\n",
    "\n",
    "The existing models in libraries like NLTK and spaCY we use to process our data (e.g. tokenization, POS, and lemmatization in this example) are generally trained and evaluated on corpora of formal writing (especailly news articles). This means that using transcriptions introduces some friction here, as we must either accept some negative impact to our results due to this domain mismatch, or invest in addressing these issues with things like pre- and post- processing steps or taking the time to find or train models that perform better on transcribed speech.\n",
    "\n",
    "## What is something you'd like to try if you had another 8 hours? 3 days? 1 week?\n",
    "Given another 8 hours:\n",
    "* Take some more time to familiarize myself with the contents of the datasets. I'd look for things like formatting differences, domain/style differences, and common stopwords.\n",
    "* Have some conversations with stakeholders to determine priorities here. What are we doing with these topic models? It's difficult to assess them or prioritize without that context.\n",
    "* I'm not terribly fond of working in notebooks. I'd prefer to move most of the functions out of the notebook context and only use it for some final processing and sharing results.\n",
    "* Influenced by the above, I'd spend more time pre-processing the data. I've already noticed, for example, that some of the data seem to be missing linebreaks. This could potentially be addressed with some heuristic pre-processing to re-insert breaks where we could reliably predict them with a regex pattern.\n",
    "* I'd add some nicer summary statistics and visualizations. I gave some fun TSNE reduction and clustering a shot, but it's not terribly informative at this point and without taking the time to add tooltips/labels!\n",
    "\n",
    "Given 3 days:\n",
    "* Look more into other topic modeling methods. There are some good end-to-end neural methods out there that might be quick to implement and evaluate.\n",
    "* Can we get more data? It's a pretty small dataset!\n",
    "* If feasable with the amount of data, set up a validation dataset so I can more confidently do parameter tuning of the LDA itself and/or other models.\n",
    "\n",
    "Given 1 week:\n",
    "* Given more time, depending on the broader goals, I'd probably prefer to use a supervised labeling method and take the time to manually label a dataset.\n",
    "* At this point, it would also be worth looking into the broader project pipeline and ensure that things are set up in a way that's going to be reliable and repeatable.\n",
    "\n",
    "\n",
    "## What are the tradeoffs between using LDA for topic modeling vs other methods?\n",
    "That LDA is unsupervised means we can quickly see what kind of distinctions arise naturally from the distributions of tokens in the documents. Especially for early exploratory work, it's great to be able to get results these without having to source or create a labeled dataset.\n",
    "\n",
    "There are a few challenges with LDA and similar unsupervised methods, however. First, there's not really any well established way to set the correct number of topics. It's possible to look at things like perplexity and model coherence to evaluate how well a model does with a given number of topics, but there's always some complexity and subjectivity here. \n",
    "\n",
    "Second, the topics are associated with keywords, but there's not necessarily an intuitive mapping to something we'd normally think of as a topic. We might often be able to look at the set of associated tokens and assign some sensible topic gloss, but this isn't guaranteed and may not actually be a great representation of the model's own internal process.\n",
    "\n",
    "Third, these topics will change if we change our training data. It can be challenging to build reliable products downstream of an LDA model, as we can't easily guarantee the stability of the topics.\n",
    "\n",
    "## Machine transcriptions have more mistakes than human transcriptions. If we only had access to a large amount of machine transcriptions, what are some strategies we could try to still have decent topic modeling?\n",
    "The first step here would be some re-working of the data preparation pipeline to be a little more tolerent of these errors. I know from experience that neither the NLTK nor spaCY sentence tokenizer or POS annotator work well on machine transcriptions. There are some basic pre-and post processing rules here that can catch a lot of the common errors and patch things back together.\n",
    "\n",
    "Machine transcription systems are generally trained and tested on generalized domains, meaning they will often make errors in technical and specialized domains. To take a concrete example I've seen, the prior probability of the phrase \"a sauna\" in a general corpus is much higher than the homophonic work management platform \"Asana.\" Given the resources, fine-tuning a transcription model to fit the domain could improve results, but this would be expensive to do per-domain. Short of that, some post-hoc correction could likely yield good results. The simplest version could be a set of pattern matchers and substitutions, but it could also be interesting to model in more depth with some kind of phonemic representation of the text in combination with token frequencies collected from in domain data. For example, we could evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7386dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim import corpora, models\n",
    "\n",
    "import nltk\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21203d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kevin/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/kevin/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /home/kevin/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/kevin/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /home/kevin/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2a5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f055dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lda_corpus(tokens, dictionary=None):\n",
    "    if not dictionary:\n",
    "        dictionary = corpora.Dictionary(tokens)\n",
    "    \n",
    "        # Consider parameterizing the no_below here?\n",
    "        dictionary.filter_extremes(no_below=0)\n",
    "    \n",
    "    # Corpus consists of a BOW representation for each document\n",
    "    corpus = [dictionary.doc2bow(tok) for tok in tokens]\n",
    "    \n",
    "    return corpus, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a0ac8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_tokenize(list_text):\n",
    "    df = pd.DataFrame(list_text)\n",
    "    df.columns = [\"documents\"]\n",
    "    \n",
    "    # Split each document into sentences. NLTK's sentence tokenizer isn't great out of the box.\n",
    "    # Look into other options like spacy here and consider adding some heuristic pre\n",
    "    # and post-processing rules. Great blog post by textio or grammerly on this I could dig up.\n",
    "    # I also notice that some of the data is missing newline characters. Some heuristic pre-processing could\n",
    "    # clean this up and improve sentence tokenization.\n",
    "    df['sentences'] = df.documents.map(sent_tokenize)\n",
    "    \n",
    "    # Tokenize each sentence\n",
    "    df['tokens_sentences'] = df['sentences'].map(lambda sentences: [word_tokenize(sentence) for sentence in sentences])\n",
    "    \n",
    "    # Add our POS tags to tokens\n",
    "    df['POS_tokens'] = df['tokens_sentences'].map(lambda tokens_sentences: [pos_tag(tokens) for tokens in tokens_sentences])\n",
    "    df['tokens_sentences_lemmatized'] = df['POS_tokens'].map(\n",
    "        lambda list_tokens_POS: [\n",
    "            [\n",
    "                lemmatizer.lemmatize(el[0], get_wordnet_pos(el[1])) \n",
    "                if get_wordnet_pos(el[1]) != '' else el[0] for el in tokens_POS\n",
    "            ] \n",
    "            for tokens_POS in list_tokens_POS\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Lemmatize. Would be worth investigating accuracy of lemmatizer, esp. in specific domains.\n",
    "    df['tokens'] = df['tokens_sentences_lemmatized'].map(lambda sentences: list(chain.from_iterable(sentences)))\n",
    "    \n",
    "    df['tokens'] = df['tokens'].map(lambda tokens: [token.lower() for token in tokens if token.isalpha()])\n",
    "    \n",
    "    tokens = df['tokens'].tolist()\n",
    "\n",
    "    \n",
    "    # Get bigrams and trigrams so we can use these as potential topics\n",
    "    bigram_model = Phrases(tokens)\n",
    "    trigram_model = Phrases(bigram_model[tokens], min_count=1)\n",
    "    tokens = list(trigram_model[bigram_model[tokens]])\n",
    "    \n",
    "    # Let's also filter out the stopwords after generating ngrams.\n",
    "    stop = set(stopwords.words('english'))\n",
    "    \n",
    "    # Add some common bigrams we see as well. Would do this more\n",
    "    # systematically with more time!\n",
    "    stop.update((\"they_re\", \"gon_na\", \"it_s\", \"yep\"))\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = [token for token in tokens[i] if token not in stop]\n",
    "    \n",
    "    # Add tokens back to our dataframe for reference\n",
    "    df['tokens'] = tokens\n",
    "\n",
    "    \n",
    "    return tokens, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "fcf64598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lda_model(corpus, dictionary, num_topics):\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, \\\n",
    "                                id2word=dictionary, \\\n",
    "                                passes=4, alpha=[0.01]*num_topics, \\\n",
    "                                eta=[0.01]*len(dictionary.keys()))\n",
    "    \n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f3a7431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_texts(path):\n",
    "    for f_name in os.listdir(path):\n",
    "        if f_name.split('.')[-1] == 'txt':\n",
    "            with open(os.path.join(path, f_name)) as f:\n",
    "                yield (f_name, f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3bba9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_labels(model, dictionary, topn=4):\n",
    "    topic_labels = {}\n",
    "    for i, topic in enumerate(model.get_topics()):\n",
    "        topic_labels[i] = ' '.join([\n",
    "            dictionary[topic_term_id] for topic_term_id, topic_term_weight in model.get_topic_terms(i, topn)\n",
    "        ])\n",
    "    return topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b433d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexities(train_corpus, dictionary):\n",
    "    for i in range(2, 25):\n",
    "        model = build_lda_model(train_corpus, dictionary, i)\n",
    "        print(f\"{i} topic perplexity: {model.log_perplexity(train_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "48e54e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names, train_data = zip(*iter_texts('./training_transcriptions'))\n",
    "test_names, test_data = zip(*iter_texts('./testing_transcriptions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "529677b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_df = ngram_tokenize(train_data)\n",
    "train_corpus, train_dictionary = build_lda_corpus(train_tokens)\n",
    "\n",
    "# train_df.head() # Let's take a look at what we're already doing to process the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "953f87be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, -9.384183747946363\n",
      "3, -9.552122909688178\n",
      "4, -9.659071506780863\n",
      "5, -9.75389616673836\n",
      "6, -9.792434719799113\n",
      "7, -9.794982391811114\n",
      "8, -9.880884204727359\n",
      "9, -9.994193100402038\n",
      "10, -10.044401817294121\n",
      "11, -10.043077330799306\n",
      "12, -10.0792240866462\n",
      "13, -10.23724585279351\n",
      "14, -10.205427309095876\n",
      "15, -10.360864923548714\n",
      "16, -10.46534211470692\n",
      "17, -10.403951269148664\n",
      "18, -10.598564625340051\n",
      "19, -10.895946562298404\n",
      "20, -10.945003526605488\n",
      "21, -10.718562876028342\n",
      "22, -11.004651568432363\n",
      "23, -11.334026557048944\n",
      "24, -11.043341634587847\n"
     ]
    }
   ],
   "source": [
    "# Take a look at model perplexities for different models,\n",
    "# Though we balance this with subjective informativeness of \n",
    "# numbers of topics. This would really depend on downstream use.\n",
    "# Model coherence might be useful too given more time.\n",
    "# get_perplexity(train_corpus, train_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b6a53761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_lda_model(train_corpus, train_dictionary, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a2781f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels = get_topic_labels(model, train_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3107061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens, test_df = ngram_tokenize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e490645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus, _ = build_lda_corpus(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d6693dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = list(model[test_corpus])\n",
    "data = []\n",
    "for i, name in enumerate(test_names):\n",
    "    data.append(\n",
    "        (\n",
    "            name,\n",
    "            [topic_labels[topic[0]] for topic in vector[i]],\n",
    "            [{topic[0]: topic[1] for topic in vector[i]}.get(key, 0.0) for key in topic_labels.keys()],\n",
    "            *[label in [topic[0] for topic in vector[i]] for label in topic_labels.keys()]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d98f4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(data)\n",
    "out_df.columns = (\"document\", \"labels\", \"vector\", *topic_labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "72d87a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>labels</th>\n",
       "      <th>vector</th>\n",
       "      <th>typescript twilioquest open_source event</th>\n",
       "      <th>flip language github english</th>\n",
       "      <th>snake game image chat</th>\n",
       "      <th>button corgi deploy query</th>\n",
       "      <th>react rust site javascript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local-development-of-serverless-functions-on-n...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.7278668, 0.27211905, 0.0, 0.0, 0.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>devrel-creating-high-quality-communities.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.16337556, 0.83656937, 0.0, 0.0, 0.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find-your-next-open-source-contribution.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.54691106, 0.20789461, 0.0, 0.24518697, 0.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simplify-and-unify-data-access-with-netlify-gr...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.6816203, 0.10434863, 0.13942303, 0.07460345...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>devrel-the-kick-ass-curve-steve-pousty.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.25111735, 0.061097283, 0.0, 0.6877482, 0.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>create-playful-interactive-animations.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.24619126, 0.10233799, 0.026559336, 0.618126...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>build-a-live-voting-app.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.40743235, 0.07562465, 0.0, 0.51693064, 0.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jamstack-and-headless-cms-sites-using-strapi.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.3320111, 0.08802282, 0.37302688, 0.20693406...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>devrel-building-an-enterprise-developer-market...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.24860881, 0.25960484, 0.31301042, 0.1787597...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>devrel-tomtom-first-year-of-dev-rel.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.25939736, 0.47420618, 0.060875356, 0.153870...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>reactive-state-management-using-ngrx-and-angul...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.36314178, 0.06569053, 0.018799026, 0.382304...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>devrel-a-shiny-new-developer-portal-avital-tzu...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.2591195, 0.14515252, 0.07063566, 0.510066, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>devrel-building-communities-for-junior-contrib...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.21145649, 0.118829645, 0.15573376, 0.487467...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>devrel-tips-for-growing-and-nurturing-develope...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.24623175, 0.16004005, 0.39671776, 0.1881818...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>devrel-whats-brewing-and-cooking-in-your-open-...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.23008657, 0.117848255, 0.08954558, 0.540270...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>f8-2018-developer-conference.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.4902354, 0.10562327, 0.1125309, 0.27330774,...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>devrel-kindness-engineering.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.4522044, 0.23341806, 0.13122672, 0.18313512...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>devrel-how-being-a-rabbi-prepared-me-for-dev-r...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.23276934, 0.34445104, 0.050418857, 0.183208...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>devrel-how-raising-the-bar-can-plug-a-leaky-pi...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.27351084, 0.08562865, 0.3968358, 0.15263805...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>devrel-15-years-of-resumed-experiences-doing-v...</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.16297993, 0.062057205, 0.5738017, 0.2011461...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>make-music-with-code.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.26850793, 0.099783376, 0.28419632, 0.188682...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>deploy-a-site-with-self-hosted-analytics.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.3150374, 0.0951947, 0.13109252, 0.4356327, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>devrel-your-first-100-developers.txt</td>\n",
       "      <td>[typescript twilioquest open_source event, fli...</td>\n",
       "      <td>[0.23157561, 0.12734112, 0.105524376, 0.526926...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             document  \\\n",
       "0   local-development-of-serverless-functions-on-n...   \n",
       "1        devrel-creating-high-quality-communities.txt   \n",
       "2         find-your-next-open-source-contribution.txt   \n",
       "3   simplify-and-unify-data-access-with-netlify-gr...   \n",
       "4          devrel-the-kick-ass-curve-steve-pousty.txt   \n",
       "5           create-playful-interactive-animations.txt   \n",
       "6                         build-a-live-voting-app.txt   \n",
       "7    jamstack-and-headless-cms-sites-using-strapi.txt   \n",
       "8   devrel-building-an-enterprise-developer-market...   \n",
       "9             devrel-tomtom-first-year-of-dev-rel.txt   \n",
       "10  reactive-state-management-using-ngrx-and-angul...   \n",
       "11  devrel-a-shiny-new-developer-portal-avital-tzu...   \n",
       "12  devrel-building-communities-for-junior-contrib...   \n",
       "13  devrel-tips-for-growing-and-nurturing-develope...   \n",
       "14  devrel-whats-brewing-and-cooking-in-your-open-...   \n",
       "15                   f8-2018-developer-conference.txt   \n",
       "16                    devrel-kindness-engineering.txt   \n",
       "17  devrel-how-being-a-rabbi-prepared-me-for-dev-r...   \n",
       "18  devrel-how-raising-the-bar-can-plug-a-leaky-pi...   \n",
       "19  devrel-15-years-of-resumed-experiences-doing-v...   \n",
       "20                           make-music-with-code.txt   \n",
       "21       deploy-a-site-with-self-hosted-analytics.txt   \n",
       "22               devrel-your-first-100-developers.txt   \n",
       "\n",
       "                                               labels  \\\n",
       "0   [typescript twilioquest open_source event, fli...   \n",
       "1   [typescript twilioquest open_source event, fli...   \n",
       "2   [typescript twilioquest open_source event, fli...   \n",
       "3   [typescript twilioquest open_source event, fli...   \n",
       "4   [typescript twilioquest open_source event, fli...   \n",
       "5   [typescript twilioquest open_source event, fli...   \n",
       "6   [typescript twilioquest open_source event, fli...   \n",
       "7   [typescript twilioquest open_source event, fli...   \n",
       "8   [typescript twilioquest open_source event, fli...   \n",
       "9   [typescript twilioquest open_source event, fli...   \n",
       "10  [typescript twilioquest open_source event, fli...   \n",
       "11  [typescript twilioquest open_source event, fli...   \n",
       "12  [typescript twilioquest open_source event, fli...   \n",
       "13  [typescript twilioquest open_source event, fli...   \n",
       "14  [typescript twilioquest open_source event, fli...   \n",
       "15  [typescript twilioquest open_source event, fli...   \n",
       "16  [typescript twilioquest open_source event, fli...   \n",
       "17  [typescript twilioquest open_source event, fli...   \n",
       "18  [typescript twilioquest open_source event, fli...   \n",
       "19  [typescript twilioquest open_source event, fli...   \n",
       "20  [typescript twilioquest open_source event, fli...   \n",
       "21  [typescript twilioquest open_source event, fli...   \n",
       "22  [typescript twilioquest open_source event, fli...   \n",
       "\n",
       "                                               vector  \\\n",
       "0              [0.7278668, 0.27211905, 0.0, 0.0, 0.0]   \n",
       "1             [0.16337556, 0.83656937, 0.0, 0.0, 0.0]   \n",
       "2      [0.54691106, 0.20789461, 0.0, 0.24518697, 0.0]   \n",
       "3   [0.6816203, 0.10434863, 0.13942303, 0.07460345...   \n",
       "4      [0.25111735, 0.061097283, 0.0, 0.6877482, 0.0]   \n",
       "5   [0.24619126, 0.10233799, 0.026559336, 0.618126...   \n",
       "6      [0.40743235, 0.07562465, 0.0, 0.51693064, 0.0]   \n",
       "7   [0.3320111, 0.08802282, 0.37302688, 0.20693406...   \n",
       "8   [0.24860881, 0.25960484, 0.31301042, 0.1787597...   \n",
       "9   [0.25939736, 0.47420618, 0.060875356, 0.153870...   \n",
       "10  [0.36314178, 0.06569053, 0.018799026, 0.382304...   \n",
       "11  [0.2591195, 0.14515252, 0.07063566, 0.510066, ...   \n",
       "12  [0.21145649, 0.118829645, 0.15573376, 0.487467...   \n",
       "13  [0.24623175, 0.16004005, 0.39671776, 0.1881818...   \n",
       "14  [0.23008657, 0.117848255, 0.08954558, 0.540270...   \n",
       "15  [0.4902354, 0.10562327, 0.1125309, 0.27330774,...   \n",
       "16  [0.4522044, 0.23341806, 0.13122672, 0.18313512...   \n",
       "17  [0.23276934, 0.34445104, 0.050418857, 0.183208...   \n",
       "18  [0.27351084, 0.08562865, 0.3968358, 0.15263805...   \n",
       "19  [0.16297993, 0.062057205, 0.5738017, 0.2011461...   \n",
       "20  [0.26850793, 0.099783376, 0.28419632, 0.188682...   \n",
       "21  [0.3150374, 0.0951947, 0.13109252, 0.4356327, ...   \n",
       "22  [0.23157561, 0.12734112, 0.105524376, 0.526926...   \n",
       "\n",
       "    typescript twilioquest open_source event  flip language github english  \\\n",
       "0                                       True                          True   \n",
       "1                                       True                          True   \n",
       "2                                       True                          True   \n",
       "3                                       True                          True   \n",
       "4                                       True                          True   \n",
       "5                                       True                          True   \n",
       "6                                       True                          True   \n",
       "7                                       True                          True   \n",
       "8                                       True                          True   \n",
       "9                                       True                          True   \n",
       "10                                      True                          True   \n",
       "11                                      True                          True   \n",
       "12                                      True                          True   \n",
       "13                                      True                          True   \n",
       "14                                      True                          True   \n",
       "15                                      True                          True   \n",
       "16                                      True                          True   \n",
       "17                                      True                          True   \n",
       "18                                      True                          True   \n",
       "19                                      True                          True   \n",
       "20                                      True                          True   \n",
       "21                                      True                          True   \n",
       "22                                      True                          True   \n",
       "\n",
       "    snake game image chat  button corgi deploy query  \\\n",
       "0                   False                      False   \n",
       "1                   False                      False   \n",
       "2                   False                       True   \n",
       "3                    True                       True   \n",
       "4                   False                       True   \n",
       "5                    True                       True   \n",
       "6                   False                       True   \n",
       "7                    True                       True   \n",
       "8                    True                       True   \n",
       "9                    True                       True   \n",
       "10                   True                       True   \n",
       "11                   True                       True   \n",
       "12                   True                       True   \n",
       "13                   True                       True   \n",
       "14                   True                       True   \n",
       "15                   True                       True   \n",
       "16                   True                       True   \n",
       "17                   True                       True   \n",
       "18                   True                       True   \n",
       "19                   True                       True   \n",
       "20                   True                       True   \n",
       "21                   True                       True   \n",
       "22                   True                       True   \n",
       "\n",
       "    react rust site javascript  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "5                        False  \n",
       "6                        False  \n",
       "7                        False  \n",
       "8                        False  \n",
       "9                         True  \n",
       "10                        True  \n",
       "11                        True  \n",
       "12                        True  \n",
       "13                       False  \n",
       "14                        True  \n",
       "15                        True  \n",
       "16                       False  \n",
       "17                        True  \n",
       "18                        True  \n",
       "19                       False  \n",
       "20                        True  \n",
       "21                        True  \n",
       "22                       False  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9b76cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "vectors = np.array(list(out_df['vector']))\n",
    "vec2d = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ea90d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = zip(*vec2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "327d8ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
